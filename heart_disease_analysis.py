# -*- coding: utf-8 -*-
"""Heart-Disease-Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fENve7V-zvFHXvRsm8o6an9bj3JPH8qV

## **Data Preparation**
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

from google.colab import files
data = files.upload()

data = pd.read_csv('/content/heart.csv')

data

data.head()

data.info()

x = data[data.columns[:13]]
y = data['target']

scaler = StandardScaler()
scaler.fit(x)
x = scaler.transform(x)

"""# **Exploratory Data Analysis**"""

data.describe()

data.corr()

plt.figure(figsize=(16, 6))
heatmap = sns.heatmap(data.corr(), vmACin=-1, vmax=1, annot=True)
heatmap.set_title('Korelasi Antara Variabel Variabel', fontdict={'fontsize':12}, pad=12)

"""# **Data Prepocessing**

Pengecekan Data Kosong
"""

missing_data = data.isnull().sum()
print(missing_data)

"""Pengecekan Jumlah Kategori"""

class_count_sex = data['sex'].nunique()
print("Jumlah kelas atau kategori [sex]:", class_count_sex)

class_count_cp = data['cp'].nunique()
print("Jumlah kelas atau kategori [cp]:", class_count_cp)

class_count_fbs = data['fbs'].nunique()
print("Jumlah kelas atau kategori [fbs]:", class_count_fbs)

class_count_restecg = data['restecg'].nunique()
print("Jumlah kelas atau kategori [restecg]:", class_count_restecg)

class_count_exang = data['exang'].nunique()
print("Jumlah kelas atau kategori [exang]:", class_count_exang)

class_count_slope = data['slope'].nunique()
print("Jumlah kelas atau kategori [slope]:", class_count_slope)

class_count_ca = data['ca'].nunique()
print("Jumlah kelas atau kategori [ca]:", class_count_ca)

class_count_thal = data['thal'].nunique()
print("Jumlah kelas atau kategori [thal]:", class_count_thal)

class_count_target = data['target'].nunique()
print("Jumlah kelas atau kategori [target]:", class_count_target)

"""Penghapusan Kategori Yang Tidak Sesuai"""

nilai_yang_dihapus = 4
kolom_yang_dicek = 'ca'

data = data.loc[data[kolom_yang_dicek] != nilai_yang_dihapus]

class_count_ca = data['ca'].nunique()
print("Jumlah kelas atau kategori [ca]:", class_count_ca)

nilai_yang_dihapus = 3
kolom_yang_dicek = 'thal'

data = data.loc[data[kolom_yang_dicek] != nilai_yang_dihapus]

class_count_thal = data['thal'].nunique()
print("Jumlah kelas atau kategori [thal]:", class_count_thal)

data.head()

"""Pengecekan Data Duplikat"""

data.duplicated().sum()

"""Pengecekan Outlier"""

warnings.filterwarnings('ignore')

plt.figure(figsize=(8, 6))
data.boxplot()
plt.title('Boxplot Data')
plt.ylabel('Nilai')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1

outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).sum()
print('Data Outlier:')
print(outliers)

"""Pengecekan Jumlah Data Target"""

class_counts_target = data['target'].value_counts()
print(class_counts_target)

count_target = data['target'].value_counts()

data['target'] = data['target'].astype('category')

plt.bar(data['target'].cat.categories, count_target.values, color=['blue', 'orange'])

plt.xticks([0, 1], ['0', '1'])
plt.xlim([-0.5, 1.5])

plt.title('Amount of Data based on Target')
plt.xlabel('Target')
plt.ylabel('Amount of Data')

plt.show

"""# **Data Processing**"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)

"""# **Modelling Data**

SVM
"""

m1 = "SVM"

clf = SVC()
clf.fit(x_train, y_train)

y_pred_clf = clf.predict(x_test)

accuracy1 = accuracy_score(y_test, y_pred_clf)
print("Akurasi Model:", accuracy1)

"""Naive Bayes"""

m2 = "Naive Bayes"

nb = GaussianNB()

nb.fit(x_train,y_train)

y_pred_nb = nb.predict(x_test)
accuracy2 = accuracy_score(y_test, y_pred_nb)
print("Akurasi Model:", accuracy2)

"""Random Forest

"""

m3 = "Random Forest"

rf = RandomForestClassifier(n_estimators=100, criterion="entropy",max_depth=7, min_samples_leaf=2, max_features="sqrt",random_state=2)

rf.fit(x_train,y_train)

y_pred_rf = rf.predict(x_test)
accuracy3 = accuracy_score(y_test, y_pred_rf)
print("Akurasi Model:", accuracy3)

"""# **Evaluasi**

SVM
"""

report1 = classification_report(y_test, y_pred_clf)
print("Classification Report:")
print(report1)

conf_matrix1 = confusion_matrix(y_test, y_pred_clf)
print("Confusion Matrix:")
print(conf_matrix1)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix1, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""Naive Bayes"""

report2 = classification_report(y_test, y_pred_nb)
print("Classification Report:")
print(report2)

conf_matrix2 = confusion_matrix(y_test, y_pred_nb)
print("Confusion Matrix:")
print(conf_matrix2)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix2, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""Random Forest"""

report3 = classification_report(y_test, y_pred_rf)
print("Classification Report:")
print(report3)

conf_matrix3 = confusion_matrix(y_test, y_pred_rf)
print("Confusion Matrix:")
print(conf_matrix3)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix3, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""Result"""

results = {"Models": [m1, m2, m3],
           "Accuracy": [accuracy1, accuracy2, accuracy3]}

for (key, value) in results.items():
    if key=="Accuracy":
        results[key]=  [item*100 for item in results[key]]


result_data=pd.DataFrame(results)

result_data

colors = ['red','green','blue']
plt.figure(figsize=(12,5))
plt.title("barplot Represent Accuracy of different models")
plt.xlabel("Algorithms")
plt.ylabel("Accuracy %")
plt.bar(result_data['Models'],result_data['Accuracy'],color = colors)
plt.show()